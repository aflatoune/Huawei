{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huawei Research France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Le réseau d'accès optique (OAN) est une solution courante de réseau d'accès domestique à large bande dans le monde entier. Il relie les abonnés des terminaux à leur fournisseur de services. Les défaillances du réseau affectent à la fois la qualité du service (QoS) et l'expérience de l'utilisateur (la qualité d'expérience QoE). Pour réduire les dommages, il est important de prévoir à l'avance les défaillances du réseau et de les réparer à temps. Les algorithmes d'apprentissage machine (ML) ont été largement utilisés comme solution pour construire ces modèles de prédiction des pannes. \n",
    "\n",
    "Cependant, la plupart des modèles d'apprentissage automatique sont spécifiques aux données et ont tendance à se dégrader lorsque la distribution des données change. Le premier défi de données de Huawei France de cette année vise à résoudre ce problème. \n",
    "\n",
    "Vous recevrez un ensemble de données étiquetées sur le réseau d'accès optique d'une ville que nous appelons \"A\" (que nous appelons le domaine source) et un ensemble de données pour la plupart non étiquetées d'une ville \"B\" (que nous appelons le domaine cible).\n",
    "\n",
    "On vous demande de construire une solution d'apprentissage par transfert en utilisant les données sources étiquetées et les données cibles non étiquetées pour entraîner un modèle de prédiction de panne pour la ville B. Il s'agit d'un **problème d'adaptation de domaine non supervisée (UDA)**. Pour être précis, nous incluons un petit nombre de points cibles étiquetés dans l'ensemble d'entraînement, de sorte que nous pouvons appeler cette configuration \"UDA à quelques coups\" ou \"adaptation de domaine semi-supervisée\".\n",
    "\n",
    "\n",
    "1. **valeurs manquantes** : il y a beaucoup de valeurs manquantes dans les données ;\n",
    "2. **séries temporelles de données de capteurs** ;\n",
    "3. **déséquilibre des classes** : les défaillances du réseau sont rares, il s'agit donc d'un problème de classification très déséquilibré. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "Les technologies de transmission ont évolué pour intégrer les technologies optiques jusque dans les réseaux d'accès, au plus près de l'abonné. Actuellement, la fibre optique est le support de transmission par excellence en raison de sa capacité à propager le signal sur de longues distances sans régénération, de sa faible latence et de sa très grande largeur de bande. La fibre optique, initialement déployée dans les réseaux à très longue distance et à très haut débit, tend aujourd'hui à se généraliser pour offrir des services plus grand public en termes de bande passante. Il s'agit des technologies FTTH pour \"Fiber to the Home \".\n",
    "\n",
    "Le FTTH généralement adopté par les opérateurs est une architecture PON (Passive Optical Network). Le PON est une architecture point à multipoint basée sur les éléments suivants :\n",
    "- Une infrastructure de fibre optique partagée. L'utilisation de coupleurs optiques dans le réseau est la base de l'architecture et de l'ingénierie de déploiement. Les coupleurs sont utilisés pour desservir plusieurs zones ou plusieurs abonnés.\n",
    "\n",
    "\n",
    "- Equipement central faisant office de terminaison de ligne optique (OLT). L'OLT gère la diffusion et la réception des flux à travers les interfaces du réseau. Il reçoit les signaux des abonnés et diffuse un contenu basé sur des services spécifiques. \n",
    "\n",
    "\n",
    "- Équipements terminaux :\n",
    "    - ONT (Optical Network Terminations) dans le cas où l'équipement est dédié à un client et que la fibre atteint le client. Il s'agit alors d'une architecture de type FTTH (Fiber To The Home). Il n'y a qu'une seule fibre par client (les signaux sont bidirectionnels).\n",
    "    - ONU (Optical Network Unit) dans le cas où l'équipement est dédié à un bâtiment entier. Il s'agit alors d'une architecture de type FTTB (Fiber To The Building).\n",
    "\n",
    "    \n",
    "<img src=\"https://image.makewebeasy.net/makeweb/0/p4Ky6EVg4/optical%20fiber-knowledge/Apps_FTTx_Fig3.png\">\n",
    "\n",
    "Les données pour ce défi sont collectées à partir de capteurs au niveau de l'ONT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les données\n",
    "\n",
    "Les données proviennent de deux villes différentes : la ville A (la source) et la ville B (la cible). Les données sont étiquetées pour la ville A mais (principalement) non étiquetées pour la ville B (seulement 20% des données étiquetées sont connues pour la ville B). Pour les deux villes A et B, les données sont une série temporelle collectée pendant environ 60 jours. La granularité de la série temporelle est de 15 minutes. Les échantillons représentent différents utilisateurs (donc différents ONT). A chaque pas de temps, nous disposons d'une mesure en dix dimensions des caractéristiques suivantes (entre parenthèses, les unités de chaque caractéristique).\n",
    "\n",
    "- **current** : courant de polarisation du module optique de l'ONT GPON (mA)\n",
    "- **err_down_bip** : nombre de trames descendantes ONT avec erreur BIP (entier)\n",
    "- **err_up_bip** : nombre de trames ONT amont avec erreur BIP (entier)\n",
    "- **olt_recv** : puissance de réception du module optique GPON ONT de l'ONU (dBm)\n",
    "- **rdown** : débit descendant de l'ONT GPON (Mbs)\n",
    "- **recv** : puissance de réception du module optique GPON ONT (dBm)\n",
    "- **rup** : débit amont de l'ONT GPON (Mbs)\n",
    "- **send** : puissance d'émission du module optique GPON ONT (dBm)\n",
    "- **temp** : température du module optique GPON ONT (Celsius)\n",
    "- **volt** : tension d'alimentation du module optique GPON ONT (mV)\n",
    "- **étiquettes** : 0 (faible) ou 1 (échec) pour l'échantillon. \n",
    "\n",
    "L'objectif du défi est de séparer le faible de l'échec, les bonnes données sont juste données comme information secondaire (pouvant être utilisées pour la calibration), ainsi l'objectif est de soumettre un classificateur binaire.\n",
    "\n",
    "Soit $x_t$ l'échantillon collecté au jour $t$, alors l'étiquette correspondante est calculée au jour $t+7$. Notre objectif est de prédire un échec à partir de données provenant de 7 jours auparavant.  \n",
    "\n",
    "\n",
    "Les données sont données avec la forme **[users, timestamps, features]** et les features sont données dans le même ordre que celui présenté ci-dessus. Pour chaque utilisateur et chaque horodatage, nous agrégeons sept jours de données.\n",
    "\n",
    "Notez que l'ensemble de données publiques (qui vous est remis avec le kit de démarrage) et l'ensemble de données privées (utilisé pour évaluer vos soumissions sur le serveur) proviennent de la même distribution, donc en principe vous pourriez utiliser les données cibles publiques étiquetées pour apprendre un classificateur et soumettre la fonction réelle. Cela irait à l'encontre de l'objectif de l'apprentissage par transfert, nous avons donc décidé de transformer légèrement mais significativement l'ensemble de données privées pour rendre cette stratégie non performante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>err_down_bip</th>\n",
       "      <th>err_up_bip</th>\n",
       "      <th>olt_recv</th>\n",
       "      <th>rdown</th>\n",
       "      <th>recv</th>\n",
       "      <th>rup</th>\n",
       "      <th>send</th>\n",
       "      <th>temp</th>\n",
       "      <th>volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.32</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.35</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.19</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   current  err_down_bip  err_up_bip  olt_recv  rdown       recv    rup  send  \\\n",
       "0     13.0         563.0        25.0       NaN  0.003 -30.459999  0.001  2.32   \n",
       "1     13.0         541.0        48.0       NaN  0.001 -30.459999  0.001  2.25   \n",
       "2     13.0         587.0        68.0       NaN  0.001 -30.459999  0.001  2.35   \n",
       "3     13.0         641.0        79.0       NaN  0.001 -30.459999  0.001  2.23   \n",
       "4     13.0         585.0        96.0       NaN  0.000 -30.459999  0.001  2.19   \n",
       "\n",
       "   temp    volt  \n",
       "0  45.0  3300.0  \n",
       "1  45.0  3300.0  \n",
       "2  45.0  3300.0  \n",
       "3  45.0  3300.0  \n",
       "4  45.0  3300.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 20\n",
    "\n",
    "test = pd.DataFrame(X_train.source[sample], columns=[\"current\", \n",
    "                                          \"err_down_bip\", \n",
    "                                          \"err_up_bip\", \n",
    "                                          \"olt_recv\", \n",
    "                                          \"rdown\", \n",
    "                                          \"recv\", \n",
    "                                          \"rup\",\n",
    "                                          \"send\", \"temp\", \"volt\"])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>err_down_bip</th>\n",
       "      <th>err_up_bip</th>\n",
       "      <th>olt_recv</th>\n",
       "      <th>rdown</th>\n",
       "      <th>recv</th>\n",
       "      <th>rup</th>\n",
       "      <th>send</th>\n",
       "      <th>temp</th>\n",
       "      <th>volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.00000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.660714</td>\n",
       "      <td>733.159241</td>\n",
       "      <td>54.818451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576213</td>\n",
       "      <td>-30.460159</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>2.26110</td>\n",
       "      <td>44.453869</td>\n",
       "      <td>3299.970215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473820</td>\n",
       "      <td>208.409286</td>\n",
       "      <td>86.458672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.941489</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.05637</td>\n",
       "      <td>0.701891</td>\n",
       "      <td>0.771516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.16000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.22000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>825.250000</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>597.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.476000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>2.36000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          current  err_down_bip  err_up_bip  olt_recv       rdown        recv  \\\n",
       "count  672.000000    672.000000  672.000000       0.0  672.000000  672.000000   \n",
       "mean    12.660714    733.159241   54.818451       NaN    0.576213  -30.460159   \n",
       "std      0.473820    208.409286   86.458672       NaN    1.941489    0.000160   \n",
       "min     12.000000    412.000000    0.000000       NaN    0.000000  -30.459999   \n",
       "25%     12.000000    631.000000    9.000000       NaN    0.001000  -30.459999   \n",
       "50%     13.000000    753.000000   27.000000       NaN    0.001000  -30.459999   \n",
       "75%     13.000000    825.250000   65.250000       NaN    0.102500  -30.459999   \n",
       "max     13.000000   4649.000000  597.000000       NaN   20.476000  -30.459999   \n",
       "\n",
       "              rup       send        temp         volt  \n",
       "count  672.000000  672.00000  672.000000   672.000000  \n",
       "mean     0.010720    2.26110   44.453869  3299.970215  \n",
       "std      0.026105    0.05637    0.701891     0.771516  \n",
       "min      0.000000    2.16000   43.000000  3280.000000  \n",
       "25%      0.001000    2.22000   44.000000  3300.000000  \n",
       "50%      0.001000    2.26000   44.000000  3300.000000  \n",
       "75%      0.007000    2.31000   45.000000  3300.000000  \n",
       "max      0.317000    2.36000   46.000000  3300.000000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données manquantes\n",
    "\n",
    "Vous remarquerez que certaines données sont manquantes dans les ensembles de données. Il peut y avoir plusieurs raisons :\n",
    "\n",
    "1. Aucune donnée n'a été collectée à une date spécifique pour un utilisateur spécifique.\n",
    "2. Le processus de collecte des données ne parvient pas à récupérer une caractéristique.\n",
    "    \n",
    "Cela fait partie du défi de surmonter cette difficulté de la vie réelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métriques\n",
    "\n",
    "- Accuracy (**acc**): Le nombre d'étiquettes correctement prédites par rapport au nombre total d'échantillons.  [sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score). \n",
    "- Area unther the ROC curve (**auc**). Ce score nous donne la probabilité qu'une instance d'échec soit mieux notée qu'une instance faible par la fonction discriminante binaire [sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html).\n",
    "- Average precision (**ap**): il résume une courbe précision-rappel sous la forme de la moyenne pondérée des précisions obtenues à chaque seuil, l'augmentation du rappel par rapport au seuil précédent étant utilisée comme poids [sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score).\n",
    "- **Precision@Recall**: est un score hybride implémenté dans `utils.scores`. Il calcule la précision lorsque le rappel est à un certain pourcentage, c'est-à-dire, recall est la précision lorsque le rappel est à k%.\n",
    "\n",
    "**NOTE : Average precision (ap) est la métrique officiel d'évaluation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour installer `ramp-workflow`:\n",
    "```\n",
    "pip install git+https://github.com/paris-saclay-cds/ramp-workflow.git\n",
    "```\n",
    "\n",
    "Cette commande installera la bibliothèque `rampwf` et le script `ramp-test` que vous pouvez utiliser pour vérifier votre soumission avant de la soumettre. Vous n'avez pas besoin de connaître ce paquetage pour participer au défi, mais il pourrait être utile de jeter un coup d'œil à la [documentation](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/index.html) si vous souhaitez savoir ce qui se passe lorsque nous testons votre modèle, en particulier la page [exécution RAMP](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/scoring.html) pour comprendre `ramp-test`, et les [commandes](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/command_line.html) pour comprendre les différentes options de la ligne de commande. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rampwf as rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = rw.utils.assert_read_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les données\n",
    "\n",
    "Exécutez le script `prepare_data.py` dans `./data`. Notez que les données publiques qui vous sont données sont différentes des données privées utilisées pour évaluer vos soumissions sur le serveur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données d'apprentissage sont composées de données source et cible provenant respectivement de la ville A et de la ville B. \n",
    "\n",
    "Dans la vie réelle, le problème FTTH comporte trois classes : \n",
    "\n",
    "- 1) le débit est normal et tout se passe bien (bon), \n",
    "- 2) le débit est faible mais la connexion fonctionne toujours (faible), \n",
    "- 3) défaillance. \n",
    "\n",
    "Pour la détection des défaillances de l'OAN, nous sommes intéressés par une classification binaire entre les deux classes : **[faible, échec]**.\n",
    "\n",
    "Vous êtes libre d'exploiter les données de la bonne classe, mais lors de la notation, vous n'êtes jugé que sur la classification binaire.\n",
    "\n",
    "**Les données sources**\n",
    "- X_train.source : Les données pour les classes faible et défaillante.\n",
    "- X_train.source_bkg : Données pour la classe bonne.\n",
    "- y_train.source : Étiquettes pour X_train.source, 0 : faible et 1 : échec.\n",
    "   \n",
    "**Les données cibles**\n",
    " - X_train.target : Données cibles (étiquetées) pour les classes faible et échec.\n",
    " - X_train.target_unlabeled : Données cibles non étiquetées.\n",
    " - X_train.target_bkg : Données cibles pour la classe bonne.\n",
    " - y_train.target : Étiquettes pour X_train.target, 0 : faible et 1 : échec.\n",
    "\n",
    "Puisque nous nous intéressons à la performance du classificateur sur les données cibles, l'ensemble de test est composé entièrement de données cibles. predict recevra à la fois X_test.target et X_test.target_bkg, et on s'attend à ce qu'il produise des probabilités des étiquettes faible et échec uniquement pour X_test.target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données d'entrée sont tridimensionnelles (échantillon, temps, caractéristiques). Le temps a 672 dimensions (4 fois une heure $\\times$ 24 heures $\\times$ 7 jours). Il contient des valeurs nan, il doit donc être nettoyé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.source[6].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Vous devez soumettre un extracteur de caractéristiques et un classificateur. La fonction transform de l'extracteur de caractéristiques est exécutée sur chaque donnée d'entrée (cible, source, bkg) et les tableaux résultants sont passés aux fonctions fit et predict du classificateur. L'extracteur de caractéristiques du kit de départ remplace nans par zéro, et aplatit la matrice en **(sample, 6720)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/source_rf/feature_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submissions/source_rf/feature_extractor.py\n",
    "import numpy as np\n",
    "\n",
    "class FeatureExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Deal with NaNs inplace\n",
    "        np.nan_to_num(X, copy=False)\n",
    "        # We flatten the input, originally 3D (sample, time, dim) to\n",
    "        # 2D (sample, time * dim)\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting kit implements a naive domain adaptation where the model (random forest) trained on the source is used to classify the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/source_rf/classifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submissions/source_rf/classifier.py\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils.dataset import OpticalDataset, OpticalLabels\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clf = LGBMClassifier(\n",
    "            n_estimators=50, \n",
    "            max_depth=20, \n",
    "            random_state=44, \n",
    "            num_leaves=31,\n",
    "            n_jobs=-1)\n",
    "        print(self.clf)\n",
    "\n",
    "    def fit(self, X_source, X_source_bkg, X_target, X_target_unlabeled,\n",
    "            X_target_bkg, y_source, y_target):\n",
    "        self.clf.fit(X_source, y_source)\n",
    "\n",
    "    def predict_proba(self, X_target, X_target_bkg):\n",
    "        y_proba = self.clf.predict_proba(X_target)\n",
    "        return y_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez regarder le code du flux de travail à `external_imports/utils/workflow.py` pour voir exactement comment vos soumissions sont chargées et utilisées. Vous pouvez exécuter l'entraînement et la prédiction de votre soumission ici dans le notebook. Lorsque vous exécutez `ramp-test`, nous faisons une validation croisée ; ici vous utilisez les données complètes de formation pour former et les données de test pour tester. [Cette page](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/scoring.html) vous donne un bref aperçu de ce qui se passe en coulisses lorsque vous exécutez le script `ramp-test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Optical Dataset composed of\n",
       "46110 source samples\n",
       "50862 source background samples\n",
       "438 target labeled samples\n",
       "8202 target unlabeled samples\n",
       "29592 target background samples"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(max_depth=20, n_estimators=50, random_state=44)\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "trained_workflow = problem.workflow.train_submission('submissions/source_rf', X_train, y_train)\n",
    "y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scores\n",
    "\n",
    "Nous calculons six scores sur la classification. Tous les scores sont implémentés dans `external_imports.utils.scores.py` donc vous pouvez regarder les définitions précises là. Le score officiel de la compétition est ap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap    = problem.score_types[0]\n",
    "rec5  = problem.score_types[1]\n",
    "rec10 = problem.score_types[2]\n",
    "rec20 = problem.score_types[3]\n",
    "acc   = problem.score_types[4]\n",
    "auc   = problem.score_types[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap test score    = 0.1838770011572445\n",
      "rec5 test score  = 0.08674804121255875\n",
      "rec10 test score = 0.16564951837062836\n",
      "rec20 test score = 0.32083696126937866\n",
      "acc test score   = 0.823234598490821\n",
      "auc test score   = 0.6293792968994895\n"
     ]
    }
   ],
   "source": [
    "print('ap test score    = {}'.format(ap(y_test.target, y_test_pred[:,1])))\n",
    "print('rec5 test score  = {}'.format(rec5(y_test.target, y_test_pred[:,1])))\n",
    "print('rec10 test score = {}'.format(rec10(y_test.target, y_test_pred[:,1])))\n",
    "print('rec20 test score = {}'.format(rec20(y_test.target, y_test_pred[:,1])))\n",
    "print('acc test score   = {}'.format(acc(y_test.target, y_test_pred.argmax(axis=1))))\n",
    "print('auc test score   = {}'.format(auc(y_test.target, y_test_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cross validation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons une validation croisée dix fois (stratifiée lorsque les étiquettes sont disponibles) pour tous les ensembles de données. Dans chaque split, 20% des instances sont dans l'ensemble de validation, à l'exception des données cibles étiquetées qui servent principalement à la validation (pour obtenir une estimation non biaisée des scores de test, évalués entièrement sur des échantillons cibles étiquetés). Nous plaçons vingt points cibles étiquetés dans les splits d'entraînement. La raison en est que lorsque nous étendons nos services à large bande à la ville B, nous pouvons obtenir rapidement un petit ensemble de données étiquetées, mais nous aimerions déployer notre détecteur de défaillance sans attendre deux mois pour recueillir des données comparables à celles de la ville A.\n",
    "\n",
    "Le schéma de validation croisée (voir `problem.get_cv`) est implémenté dans la classe `TLShuffleSplit` de `external_imports.utils.cv.py`, si vous voulez y regarder de plus près.\n",
    "\n",
    "Vous êtes libre de jouer avec la coupure train/test et la validation croisée lors du développement de vos modèles mais sachez que nous utiliserons la même configuration sur le serveur officiel que celle du kit RAMP (sur un ensemble différent de quatre campagnes qui ne sera pas disponible pour vous).\n",
    "\n",
    "La cellule suivante passe par les mêmes étapes que le script d'évaluation officiel (`ramp-test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = problem.get_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "training ap on fold 0 = 0.30833333333333335\n",
      "validation ap on fold 0 = 0.2637875964895809\n",
      "test ap on fold 0 = 0.16218430339780684\n",
      "-------------------------------------\n",
      "training ap on fold 1 = 0.21250000000000002\n",
      "validation ap on fold 1 = 0.2555942077788053\n",
      "test ap on fold 1 = 0.16361016472786805\n",
      "-------------------------------------\n",
      "training ap on fold 2 = 0.2\n",
      "validation ap on fold 2 = 0.29440601825201235\n",
      "test ap on fold 2 = 0.1745388926023523\n",
      "-------------------------------------\n",
      "training ap on fold 3 = 0.7375\n",
      "validation ap on fold 3 = 0.28218715512682335\n",
      "test ap on fold 3 = 0.16904411795376056\n",
      "-------------------------------------\n",
      "training ap on fold 4 = 0.21250000000000002\n",
      "validation ap on fold 4 = 0.24879604051634688\n",
      "test ap on fold 4 = 0.16172210972525408\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9f973a367edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_is\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_is\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     trained_workflow = problem.workflow.train_submission(\n\u001b[0m\u001b[1;32m      6\u001b[0m         'submissions/starting_kit', X_train, y_train, train_is)\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_fold_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_is\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Draft/OAN/external_imports/utils/workflow.py\u001b[0m in \u001b[0;36mtrain_submission\u001b[0;34m(self, module_path, X, y, fold)\u001b[0m\n\u001b[1;32m     59\u001b[0m         X = OpticalDataset(\n\u001b[1;32m     60\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_bkg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_bkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_unlabeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_unlabeled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = problem.get_cv(X_train, y_train)\n",
    "\n",
    "y_test_preds = []\n",
    "for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "    trained_workflow = problem.workflow.train_submission(\n",
    "        'submissions/starting_kit', X_train, y_train, train_is)\n",
    "    X_fold_train = X_train.slice(train_is)\n",
    "    X_fold_valid = X_train.slice(valid_is)\n",
    "    \n",
    "    y_train_pred = problem.workflow.test_submission(trained_workflow, X_fold_train)\n",
    "    y_valid_pred = problem.workflow.test_submission(trained_workflow, X_fold_valid)\n",
    "    y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "    print('-------------------------------------')\n",
    "    print('training ap on fold {} = {}'.format(\n",
    "        fold_i, ap(y_train.slice(train_is).target, y_train_pred[:,1])))\n",
    "    print('validation ap on fold {} = {}'.format(\n",
    "        fold_i, ap(y_train.slice(valid_is).target, y_valid_pred[:,1])))\n",
    "    print('test ap on fold {} = {}'.format(fold_i, ap(y_test.target, y_test_pred[:,1])))\n",
    "    \n",
    "    y_test_preds.append(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous calculons à la fois le score moyen du test et le score de la mise en sac de vos dix modèles. Le classement officiel sera déterminé par le score de test mis en sac (sur des ensembles de données différents de ceux dont vous disposez). Votre score public sera le score de validation mis en sac (le calcul de la moyenne est [légèrement plus compliqué](https://github.com/paris-saclay-cds/ramp-workflow/blob/master/rampwf/utils/combine.py#L56) car nous devons nous occuper correctement des masques de validation croisée). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ap score = 0.1662199176814084\n",
      "Bagged ap score = 0.1688256992369087\n"
     ]
    }
   ],
   "source": [
    "bagged_y_pred = np.array(y_test_preds).mean(axis=0)\n",
    "print('Mean ap score = {}'.format(\n",
    "    np.mean([ap(y_test.target, y_test_pred[:,1]) for y_test_pred in y_test_preds])))\n",
    "print('Bagged ap score = {}'.format(\n",
    "    ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple submissions\n",
    "\n",
    "Outre le kit de départ, nous vous proposons deux autres exemples de soumissions. L'extracteur de caractéristiques est le même dans les trois. `source_rf` est similaire au kit de départ, mais utilise des arbres plus nombreux et plus profonds, pour obtenir un meilleur score. `target_rf` est une autre soumission extrême qui utilise seulement l'instance d'entraînement de la cible (peu) étiquetée pour apprendre un classificateur. Il a une performance légèrement moins bonne que `source_rf` ce qui signifie que les données sources améliorent le classificateur même si les distributions sources et cibles sont différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultats:\n",
    "|          | ap             | rec-5         | rec-10         | rec-20         | acc            |  auc           | \n",
    "|:---------|:--------------:|:-------------:|:--------------:|:--------------:|:--------------:|:--------------:|   \n",
    "|source_rf | 0.191 ± 0.0026 | 0.073 ± 0.002 | 0.176 ± 0.0032 | 0.357 ± 0.0075 | 0.84 ± 0.0014  | 0.637 ± 0.0063 | \n",
    "|target_rf | 0.163 ± 0.0218 | 0.067 ± 0.0182| 0.138 ± 0.0339 | 0.272 ± 0.0537 | 0.813 ± 0.036  | 0.591 ± 0.0399 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La grande question de l'apprentissage par transfert à résoudre est la suivante : **Comment combiner les données cibles à faible biais et à haute variance avec les données sources à faible biais et à haute variance**. D'autres questions auxquelles nous nous attendons à voir des réponses :\n",
    "\n",
    "1. Peut-on faire un meilleur prétraitement (amputation des données manquantes, utilisation du temps d'une manière plus intelligente) dans l'extracteur de caractéristiques ?\n",
    "2. Normalement, les données d'arrière-plan (bonnes instances) ne participent pas au scoring, mais elles peuvent informer le classifieur du changement de distribution. Comment utiliser au mieux cette information ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local testing (before submission)\n",
    "\n",
    "You submission will contain a `feature_extractor.py` implementing a FeatureExtractor class with a `transform` function (no `fit`) and a `classifier.py` implementing a Classifier class with a `fit` and `predict_proba` functions as in the starting kit. You should place it in the `submission/<submission_name>` folder in your RAMP kit folder. To test your submission, go to your RAMP kit folder in the terminal and type\n",
    "```\n",
    "ramp-test --submission <submission_name>\n",
    "```\n",
    "It will train and test your submission much like we did it above in this notebook, and print the foldwise and summary scores. You can try it also in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ramp-test --submission target_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a local leaderboard, use the `--save-output` option when running `ramp-test`, then try `ramp-show leaderboard` with different options. For example:\n",
    "```\n",
    "ramp-show leaderboard --mean --metric \"['ap','auc']\" --step \"['valid','test']\" --precision 3\n",
    "```\n",
    "and\n",
    "```\n",
    "ramp-show leaderboard --bagged --metric \"['auc']\"\n",
    "```\n",
    "\n",
    "RAMP also has an experimental hyperopt feature, with random grid search implemented. If you want to use it, type\n",
    "```\n",
    "ramp-hyperopt --help\n",
    "```\n",
    "and check out the example submission [here](https://github.com/ramp-kits/titanic/tree/hyperopt/submissions/starting_kit_h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact\n",
    "\n",
    "You can contact the organizers in the Slack of the challenge, join by [clicking here](https://join.slack.com/t/huaweiramp/shared_invite/zt-qbf4vy9s-0NS4~V898h40x8cI2KHEfQ). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
