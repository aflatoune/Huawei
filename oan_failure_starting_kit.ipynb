{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huawei Research France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:37:24.212303Z",
     "start_time": "2021-06-24T15:37:24.148072Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rampwf as rw\n",
    "import datetime\n",
    "import time\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:37:24.336717Z",
     "start_time": "2021-06-24T15:37:24.289878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'extract' from 'C:\\\\Users\\\\Daniel\\\\Desktop\\\\projets\\\\Huawei\\\\extract.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import extract\n",
    "from extract import PrepareExtractor\n",
    "from DataCleaner import DataCleaner\n",
    "importlib.reload(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:45:53.736947Z",
     "start_time": "2021-06-24T14:45:53.706365Z"
    }
   },
   "outputs": [],
   "source": [
    "problem = rw.utils.assert_read_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:46:26.053569Z",
     "start_time": "2021-06-24T14:45:53.742341Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:46:52.138550Z",
     "start_time": "2021-06-24T14:46:26.117011Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cleaner = DataCleaner(drop_olt_recv=True)\n",
    "X_temp = data_cleaner.clean_data(X_train.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:46:53.266213Z",
     "start_time": "2021-06-24T14:46:52.144610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps :  1.0479333400726318\n"
     ]
    }
   ],
   "source": [
    "prep = PrepareExtractor()\n",
    "temp, tempp = prep.get_data(X_temp, size_sample=200, resample={'unit': 'D', 'func': 'mean'}, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:46:53.374299Z",
     "start_time": "2021-06-24T14:46:53.272722Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000-01-01 00:00:00 current</th>\n",
       "      <th>2000-01-01 00:00:00 err_down_bip</th>\n",
       "      <th>2000-01-01 00:00:00 err_up_bip</th>\n",
       "      <th>2000-01-01 00:00:00 rdown</th>\n",
       "      <th>2000-01-01 00:00:00 recv</th>\n",
       "      <th>2000-01-01 00:00:00 rup</th>\n",
       "      <th>2000-01-01 00:00:00 send</th>\n",
       "      <th>2000-01-01 00:00:00 temp</th>\n",
       "      <th>2000-01-01 00:00:00 volt</th>\n",
       "      <th>2000-01-02 00:00:00 current</th>\n",
       "      <th>...</th>\n",
       "      <th>2000-01-06 00:00:00 volt</th>\n",
       "      <th>2000-01-07 00:00:00 current</th>\n",
       "      <th>2000-01-07 00:00:00 err_down_bip</th>\n",
       "      <th>2000-01-07 00:00:00 err_up_bip</th>\n",
       "      <th>2000-01-07 00:00:00 rdown</th>\n",
       "      <th>2000-01-07 00:00:00 recv</th>\n",
       "      <th>2000-01-07 00:00:00 rup</th>\n",
       "      <th>2000-01-07 00:00:00 send</th>\n",
       "      <th>2000-01-07 00:00:00 temp</th>\n",
       "      <th>2000-01-07 00:00:00 volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>31.968750</td>\n",
       "      <td>0.820359</td>\n",
       "      <td>-30.465311</td>\n",
       "      <td>0.041641</td>\n",
       "      <td>2.264688</td>\n",
       "      <td>45.583332</td>\n",
       "      <td>3279.791748</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>14.052083</td>\n",
       "      <td>408.0</td>\n",
       "      <td>21.781250</td>\n",
       "      <td>1.282615</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.056198</td>\n",
       "      <td>2.263125</td>\n",
       "      <td>45.906250</td>\n",
       "      <td>3279.791748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.052083</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>-28.530626</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>2.132396</td>\n",
       "      <td>41.947918</td>\n",
       "      <td>3280.000000</td>\n",
       "      <td>10.958333</td>\n",
       "      <td>...</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>10.572917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.094948</td>\n",
       "      <td>-28.271250</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>2.154896</td>\n",
       "      <td>40.802082</td>\n",
       "      <td>3280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2000-01-01 00:00:00 current  2000-01-01 00:00:00 err_down_bip  \\\n",
       "0                         14.0                             408.0   \n",
       "0                         11.0                               0.0   \n",
       "\n",
       "   2000-01-01 00:00:00 err_up_bip  2000-01-01 00:00:00 rdown  \\\n",
       "0                       31.968750                   0.820359   \n",
       "0                        1.052083                   0.036052   \n",
       "\n",
       "   2000-01-01 00:00:00 recv  2000-01-01 00:00:00 rup  \\\n",
       "0                -30.465311                 0.041641   \n",
       "0                -28.530626                 0.003604   \n",
       "\n",
       "   2000-01-01 00:00:00 send  2000-01-01 00:00:00 temp  \\\n",
       "0                  2.264688                 45.583332   \n",
       "0                  2.132396                 41.947918   \n",
       "\n",
       "   2000-01-01 00:00:00 volt  2000-01-02 00:00:00 current  ...  \\\n",
       "0               3279.791748                    14.000000  ...   \n",
       "0               3280.000000                    10.958333  ...   \n",
       "\n",
       "   2000-01-06 00:00:00 volt  2000-01-07 00:00:00 current  \\\n",
       "0                    3280.0                    14.052083   \n",
       "0                    3280.0                    10.572917   \n",
       "\n",
       "   2000-01-07 00:00:00 err_down_bip  2000-01-07 00:00:00 err_up_bip  \\\n",
       "0                             408.0                       21.781250   \n",
       "0                               0.0                        0.822917   \n",
       "\n",
       "   2000-01-07 00:00:00 rdown  2000-01-07 00:00:00 recv  \\\n",
       "0                   1.282615                -30.459999   \n",
       "0                   0.094948                -28.271250   \n",
       "\n",
       "   2000-01-07 00:00:00 rup  2000-01-07 00:00:00 send  \\\n",
       "0                 0.056198                  2.263125   \n",
       "0                 0.004729                  2.154896   \n",
       "\n",
       "   2000-01-07 00:00:00 temp  2000-01-07 00:00:00 volt  \n",
       "0                 45.906250               3279.791748  \n",
       "0                 40.802082               3280.000000  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Vous devez soumettre un extracteur de caractéristiques et un classificateur. La fonction transform de l'extracteur de caractéristiques est exécutée sur chaque donnée d'entrée (cible, source, bkg) et les tableaux résultants sont passés aux fonctions fit et predict du classificateur. L'extracteur de caractéristiques du kit de départ remplace nans par zéro, et aplatit la matrice en **(sample, 6720)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:12:05.933472Z",
     "start_time": "2021-06-24T14:10:28.671521Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_workflow = problem.workflow.train_submission('submissions/prepare_rf', X_train, y_train)\n",
    "y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap    = problem.score_types[0]\n",
    "rec5  = problem.score_types[1]\n",
    "rec10 = problem.score_types[2]\n",
    "rec20 = problem.score_types[3]\n",
    "acc   = problem.score_types[4]\n",
    "auc   = problem.score_types[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ap test score    = {}'.format(ap(y_test.target, y_test_pred[:,1])))\n",
    "print('rec5 test score  = {}'.format(rec5(y_test.target, y_test_pred[:,1])))\n",
    "print('rec10 test score = {}'.format(rec10(y_test.target, y_test_pred[:,1])))\n",
    "print('rec20 test score = {}'.format(rec20(y_test.target, y_test_pred[:,1])))\n",
    "print('acc test score   = {}'.format(acc(y_test.target, y_test_pred.argmax(axis=1))))\n",
    "print('auc test score   = {}'.format(auc(y_test.target, y_test_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons une validation croisée dix fois (stratifiée lorsque les étiquettes sont disponibles) pour tous les ensembles de données. Dans chaque split, 20% des instances sont dans l'ensemble de validation, à l'exception des données cibles étiquetées qui servent principalement à la validation (pour obtenir une estimation non biaisée des scores de test, évalués entièrement sur des échantillons cibles étiquetés). Nous plaçons vingt points cibles étiquetés dans les splits d'entraînement. La raison en est que lorsque nous étendons nos services à large bande à la ville B, nous pouvons obtenir rapidement un petit ensemble de données étiquetées, mais nous aimerions déployer notre détecteur de défaillance sans attendre deux mois pour recueillir des données comparables à celles de la ville A.\n",
    "\n",
    "Le schéma de validation croisée (voir `problem.get_cv`) est implémenté dans la classe `TLShuffleSplit` de `external_imports.utils.cv.py`, si vous voulez y regarder de plus près.\n",
    "\n",
    "Vous êtes libre de jouer avec la coupure train/test et la validation croisée lors du développement de vos modèles mais sachez que nous utiliserons la même configuration sur le serveur officiel que celle du kit RAMP (sur un ensemble différent de quatre campagnes qui ne sera pas disponible pour vous).\n",
    "\n",
    "La cellule suivante passe par les mêmes étapes que le script d'évaluation officiel (`ramp-test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = problem.get_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits = problem.get_cv(X_train, y_train)\n",
    "\n",
    "y_test_preds = []\n",
    "for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "    trained_workflow = problem.workflow.train_submission(\n",
    "        'submissions/starting_kit', X_train, y_train, train_is)\n",
    "    X_fold_train = X_train.slice(train_is)\n",
    "    X_fold_valid = X_train.slice(valid_is)\n",
    "    \n",
    "    y_train_pred = problem.workflow.test_submission(trained_workflow, X_fold_train)\n",
    "    y_valid_pred = problem.workflow.test_submission(trained_workflow, X_fold_valid)\n",
    "    y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "    print('-------------------------------------')\n",
    "    print('training ap on fold {} = {}'.format(\n",
    "        fold_i, ap(y_train.slice(train_is).target, y_train_pred[:,1])))\n",
    "    print('validation ap on fold {} = {}'.format(\n",
    "        fold_i, ap(y_train.slice(valid_is).target, y_valid_pred[:,1])))\n",
    "    print('test ap on fold {} = {}'.format(fold_i, ap(y_test.target, y_test_pred[:,1])))\n",
    "    \n",
    "    y_test_preds.append(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous calculons à la fois le score moyen du test et le score de la mise en sac de vos dix modèles. Le classement officiel sera déterminé par le score de test mis en sac (sur des ensembles de données différents de ceux dont vous disposez). Votre score public sera le score de validation mis en sac (le calcul de la moyenne est [légèrement plus compliqué](https://github.com/paris-saclay-cds/ramp-workflow/blob/master/rampwf/utils/combine.py#L56) car nous devons nous occuper correctement des masques de validation croisée). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bagged_y_pred = np.array(y_test_preds).mean(axis=0)\n",
    "print('Mean ap score = {}'.format(\n",
    "    np.mean([ap(y_test.target, y_test_pred[:,1]) for y_test_pred in y_test_preds])))\n",
    "print('Bagged ap score = {}'.format(\n",
    "    ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple submissions\n",
    "\n",
    "Outre le kit de départ, nous vous proposons deux autres exemples de soumissions. L'extracteur de caractéristiques est le même dans les trois. `source_rf` est similaire au kit de départ, mais utilise des arbres plus nombreux et plus profonds, pour obtenir un meilleur score. `target_rf` est une autre soumission extrême qui utilise seulement l'instance d'entraînement de la cible (peu) étiquetée pour apprendre un classificateur. Il a une performance légèrement moins bonne que `source_rf` ce qui signifie que les données sources améliorent le classificateur même si les distributions sources et cibles sont différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultats:\n",
    "|          | ap             | rec-5         | rec-10         | rec-20         | acc            |  auc           | \n",
    "|:---------|:--------------:|:-------------:|:--------------:|:--------------:|:--------------:|:--------------:|   \n",
    "|source_rf | 0.191 ± 0.0026 | 0.073 ± 0.002 | 0.176 ± 0.0032 | 0.357 ± 0.0075 | 0.84 ± 0.0014  | 0.637 ± 0.0063 | \n",
    "|target_rf | 0.163 ± 0.0218 | 0.067 ± 0.0182| 0.138 ± 0.0339 | 0.272 ± 0.0537 | 0.813 ± 0.036  | 0.591 ± 0.0399 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La grande question de l'apprentissage par transfert à résoudre est la suivante : **Comment combiner les données cibles à faible biais et à haute variance avec les données sources à faible biais et à haute variance**. D'autres questions auxquelles nous nous attendons à voir des réponses :\n",
    "\n",
    "1. Peut-on faire un meilleur prétraitement (amputation des données manquantes, utilisation du temps d'une manière plus intelligente) dans l'extracteur de caractéristiques ?\n",
    "2. Normalement, les données d'arrière-plan (bonnes instances) ne participent pas au scoring, mais elles peuvent informer le classifieur du changement de distribution. Comment utiliser au mieux cette information ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local testing (before submission)\n",
    "\n",
    "You submission will contain a `feature_extractor.py` implementing a FeatureExtractor class with a `transform` function (no `fit`) and a `classifier.py` implementing a Classifier class with a `fit` and `predict_proba` functions as in the starting kit. You should place it in the `submission/<submission_name>` folder in your RAMP kit folder. To test your submission, go to your RAMP kit folder in the terminal and type\n",
    "```\n",
    "ramp-test --submission <submission_name>\n",
    "```\n",
    "It will train and test your submission much like we did it above in this notebook, and print the foldwise and summary scores. You can try it also in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ramp-test --submission prepare_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a local leaderboard, use the `--save-output` option when running `ramp-test`, then try `ramp-show leaderboard` with different options. For example:\n",
    "```\n",
    "ramp-show leaderboard --mean --metric \"['ap','auc']\" --step \"['valid','test']\" --precision 3\n",
    "```\n",
    "and\n",
    "```\n",
    "ramp-show leaderboard --bagged --metric \"['auc']\"\n",
    "```\n",
    "\n",
    "RAMP also has an experimental hyperopt feature, with random grid search implemented. If you want to use it, type\n",
    "```\n",
    "ramp-hyperopt --help\n",
    "```\n",
    "and check out the example submission [here](https://github.com/ramp-kits/titanic/tree/hyperopt/submissions/starting_kit_h)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
