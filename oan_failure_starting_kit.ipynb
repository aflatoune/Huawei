{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huawei Research France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>err_down_bip</th>\n",
       "      <th>err_up_bip</th>\n",
       "      <th>olt_recv</th>\n",
       "      <th>rdown</th>\n",
       "      <th>recv</th>\n",
       "      <th>rup</th>\n",
       "      <th>send</th>\n",
       "      <th>temp</th>\n",
       "      <th>volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.32</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.35</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.19</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   current  err_down_bip  err_up_bip  olt_recv  rdown       recv    rup  send  \\\n",
       "0     13.0         563.0        25.0       NaN  0.003 -30.459999  0.001  2.32   \n",
       "1     13.0         541.0        48.0       NaN  0.001 -30.459999  0.001  2.25   \n",
       "2     13.0         587.0        68.0       NaN  0.001 -30.459999  0.001  2.35   \n",
       "3     13.0         641.0        79.0       NaN  0.001 -30.459999  0.001  2.23   \n",
       "4     13.0         585.0        96.0       NaN  0.000 -30.459999  0.001  2.19   \n",
       "\n",
       "   temp    volt  \n",
       "0  45.0  3300.0  \n",
       "1  45.0  3300.0  \n",
       "2  45.0  3300.0  \n",
       "3  45.0  3300.0  \n",
       "4  45.0  3300.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 20\n",
    "\n",
    "test = pd.DataFrame(X_train.source[sample], columns=[\"current\", \n",
    "                                          \"err_down_bip\", \n",
    "                                          \"err_up_bip\", \n",
    "                                          \"olt_recv\", \n",
    "                                          \"rdown\", \n",
    "                                          \"recv\", \n",
    "                                          \"rup\",\n",
    "                                          \"send\", \"temp\", \"volt\"])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>err_down_bip</th>\n",
       "      <th>err_up_bip</th>\n",
       "      <th>olt_recv</th>\n",
       "      <th>rdown</th>\n",
       "      <th>recv</th>\n",
       "      <th>rup</th>\n",
       "      <th>send</th>\n",
       "      <th>temp</th>\n",
       "      <th>volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.00000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.660714</td>\n",
       "      <td>733.159241</td>\n",
       "      <td>54.818451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576213</td>\n",
       "      <td>-30.460159</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>2.26110</td>\n",
       "      <td>44.453869</td>\n",
       "      <td>3299.970215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473820</td>\n",
       "      <td>208.409286</td>\n",
       "      <td>86.458672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.941489</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.05637</td>\n",
       "      <td>0.701891</td>\n",
       "      <td>0.771516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.16000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.22000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>825.250000</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>597.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.476000</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>2.36000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          current  err_down_bip  err_up_bip  olt_recv       rdown        recv  \\\n",
       "count  672.000000    672.000000  672.000000       0.0  672.000000  672.000000   \n",
       "mean    12.660714    733.159241   54.818451       NaN    0.576213  -30.460159   \n",
       "std      0.473820    208.409286   86.458672       NaN    1.941489    0.000160   \n",
       "min     12.000000    412.000000    0.000000       NaN    0.000000  -30.459999   \n",
       "25%     12.000000    631.000000    9.000000       NaN    0.001000  -30.459999   \n",
       "50%     13.000000    753.000000   27.000000       NaN    0.001000  -30.459999   \n",
       "75%     13.000000    825.250000   65.250000       NaN    0.102500  -30.459999   \n",
       "max     13.000000   4649.000000  597.000000       NaN   20.476000  -30.459999   \n",
       "\n",
       "              rup       send        temp         volt  \n",
       "count  672.000000  672.00000  672.000000   672.000000  \n",
       "mean     0.010720    2.26110   44.453869  3299.970215  \n",
       "std      0.026105    0.05637    0.701891     0.771516  \n",
       "min      0.000000    2.16000   43.000000  3280.000000  \n",
       "25%      0.001000    2.22000   44.000000  3300.000000  \n",
       "50%      0.001000    2.26000   44.000000  3300.000000  \n",
       "75%      0.007000    2.31000   45.000000  3300.000000  \n",
       "max      0.317000    2.36000   46.000000  3300.000000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rampwf as rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = rw.utils.assert_read_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données d'entrée sont tridimensionnelles (échantillon, temps, caractéristiques). Le temps a 672 dimensions (4 fois une heure $\\times$ 24 heures $\\times$ 7 jours). Il contient des valeurs nan, il doit donc être nettoyé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.source[6].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Vous devez soumettre un extracteur de caractéristiques et un classificateur. La fonction transform de l'extracteur de caractéristiques est exécutée sur chaque donnée d'entrée (cible, source, bkg) et les tableaux résultants sont passés aux fonctions fit et predict du classificateur. L'extracteur de caractéristiques du kit de départ remplace nans par zéro, et aplatit la matrice en **(sample, 6720)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/source_rf/feature_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submissions/source_rf/feature_extractor.py\n",
    "import numpy as np\n",
    "\n",
    "class FeatureExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Deal with NaNs inplace\n",
    "        np.nan_to_num(X, copy=False)\n",
    "        # We flatten the input, originally 3D (sample, time, dim) to\n",
    "        # 2D (sample, time * dim)\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/source_rf/classifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submissions/source_rf/classifier.py\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils.dataset import OpticalDataset, OpticalLabels\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clf = LGBMClassifier(\n",
    "            n_estimators=50, \n",
    "            max_depth=20, \n",
    "            random_state=44, \n",
    "            num_leaves=31,\n",
    "            n_jobs=-1)\n",
    "        print(self.clf)\n",
    "\n",
    "    def fit(self, X_source, X_source_bkg, X_target, X_target_unlabeled,\n",
    "            X_target_bkg, y_source, y_target):\n",
    "        self.clf.fit(X_source, y_source)\n",
    "\n",
    "    def predict_proba(self, X_target, X_target_bkg):\n",
    "        y_proba = self.clf.predict_proba(X_target)\n",
    "        return y_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Optical Dataset composed of\n",
       "46110 source samples\n",
       "50862 source background samples\n",
       "438 target labeled samples\n",
       "8202 target unlabeled samples\n",
       "29592 target background samples"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(max_depth=20, n_estimators=50, random_state=44)\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "trained_workflow = problem.workflow.train_submission('submissions/source_rf', X_train, y_train)\n",
    "y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap    = problem.score_types[0]\n",
    "rec5  = problem.score_types[1]\n",
    "rec10 = problem.score_types[2]\n",
    "rec20 = problem.score_types[3]\n",
    "acc   = problem.score_types[4]\n",
    "auc   = problem.score_types[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap test score    = 0.1838770011572445\n",
      "rec5 test score  = 0.08674804121255875\n",
      "rec10 test score = 0.16564951837062836\n",
      "rec20 test score = 0.32083696126937866\n",
      "acc test score   = 0.823234598490821\n",
      "auc test score   = 0.6293792968994895\n"
     ]
    }
   ],
   "source": [
    "print('ap test score    = {}'.format(ap(y_test.target, y_test_pred[:,1])))\n",
    "print('rec5 test score  = {}'.format(rec5(y_test.target, y_test_pred[:,1])))\n",
    "print('rec10 test score = {}'.format(rec10(y_test.target, y_test_pred[:,1])))\n",
    "print('rec20 test score = {}'.format(rec20(y_test.target, y_test_pred[:,1])))\n",
    "print('acc test score   = {}'.format(acc(y_test.target, y_test_pred.argmax(axis=1))))\n",
    "print('auc test score   = {}'.format(auc(y_test.target, y_test_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons une validation croisée dix fois (stratifiée lorsque les étiquettes sont disponibles) pour tous les ensembles de données. Dans chaque split, 20% des instances sont dans l'ensemble de validation, à l'exception des données cibles étiquetées qui servent principalement à la validation (pour obtenir une estimation non biaisée des scores de test, évalués entièrement sur des échantillons cibles étiquetés). Nous plaçons vingt points cibles étiquetés dans les splits d'entraînement. La raison en est que lorsque nous étendons nos services à large bande à la ville B, nous pouvons obtenir rapidement un petit ensemble de données étiquetées, mais nous aimerions déployer notre détecteur de défaillance sans attendre deux mois pour recueillir des données comparables à celles de la ville A.\n",
    "\n",
    "Le schéma de validation croisée (voir `problem.get_cv`) est implémenté dans la classe `TLShuffleSplit` de `external_imports.utils.cv.py`, si vous voulez y regarder de plus près.\n",
    "\n",
    "Vous êtes libre de jouer avec la coupure train/test et la validation croisée lors du développement de vos modèles mais sachez que nous utiliserons la même configuration sur le serveur officiel que celle du kit RAMP (sur un ensemble différent de quatre campagnes qui ne sera pas disponible pour vous).\n",
    "\n",
    "La cellule suivante passe par les mêmes étapes que le script d'évaluation officiel (`ramp-test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = problem.get_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "training ap on fold 0 = 0.30833333333333335\n",
      "validation ap on fold 0 = 0.2637875964895809\n",
      "test ap on fold 0 = 0.16218430339780684\n",
      "-------------------------------------\n",
      "training ap on fold 1 = 0.21250000000000002\n",
      "validation ap on fold 1 = 0.2555942077788053\n",
      "test ap on fold 1 = 0.16361016472786805\n",
      "-------------------------------------\n",
      "training ap on fold 2 = 0.2\n",
      "validation ap on fold 2 = 0.29440601825201235\n",
      "test ap on fold 2 = 0.1745388926023523\n",
      "-------------------------------------\n",
      "training ap on fold 3 = 0.7375\n",
      "validation ap on fold 3 = 0.28218715512682335\n",
      "test ap on fold 3 = 0.16904411795376056\n",
      "-------------------------------------\n",
      "training ap on fold 4 = 0.21250000000000002\n",
      "validation ap on fold 4 = 0.24879604051634688\n",
      "test ap on fold 4 = 0.16172210972525408\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9f973a367edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_is\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_is\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     trained_workflow = problem.workflow.train_submission(\n\u001b[0m\u001b[1;32m      6\u001b[0m         'submissions/starting_kit', X_train, y_train, train_is)\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_fold_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_is\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Draft/OAN/external_imports/utils/workflow.py\u001b[0m in \u001b[0;36mtrain_submission\u001b[0;34m(self, module_path, X, y, fold)\u001b[0m\n\u001b[1;32m     59\u001b[0m         X = OpticalDataset(\n\u001b[1;32m     60\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_bkg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_bkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_unlabeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_unlabeled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = problem.get_cv(X_train, y_train)\n",
    "\n",
    "y_test_preds = []\n",
    "for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "    trained_workflow = problem.workflow.train_submission(\n",
    "        'submissions/starting_kit', X_train, y_train, train_is)\n",
    "    X_fold_train = X_train.slice(train_is)\n",
    "    X_fold_valid = X_train.slice(valid_is)\n",
    "    \n",
    "    y_train_pred = problem.workflow.test_submission(trained_workflow, X_fold_train)\n",
    "    y_valid_pred = problem.workflow.test_submission(trained_workflow, X_fold_valid)\n",
    "    y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "    print('-------------------------------------')\n",
    "    print('training ap on fold {} = {}'.format(\n",
    "        fold_i, ap(y_train.slice(train_is).target, y_train_pred[:,1])))\n",
    "    print('validation ap on fold {} = {}'.format(\n",
    "        fold_i, ap(y_train.slice(valid_is).target, y_valid_pred[:,1])))\n",
    "    print('test ap on fold {} = {}'.format(fold_i, ap(y_test.target, y_test_pred[:,1])))\n",
    "    \n",
    "    y_test_preds.append(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous calculons à la fois le score moyen du test et le score de la mise en sac de vos dix modèles. Le classement officiel sera déterminé par le score de test mis en sac (sur des ensembles de données différents de ceux dont vous disposez). Votre score public sera le score de validation mis en sac (le calcul de la moyenne est [légèrement plus compliqué](https://github.com/paris-saclay-cds/ramp-workflow/blob/master/rampwf/utils/combine.py#L56) car nous devons nous occuper correctement des masques de validation croisée). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ap score = 0.1662199176814084\n",
      "Bagged ap score = 0.1688256992369087\n"
     ]
    }
   ],
   "source": [
    "bagged_y_pred = np.array(y_test_preds).mean(axis=0)\n",
    "print('Mean ap score = {}'.format(\n",
    "    np.mean([ap(y_test.target, y_test_pred[:,1]) for y_test_pred in y_test_preds])))\n",
    "print('Bagged ap score = {}'.format(\n",
    "    ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple submissions\n",
    "\n",
    "Outre le kit de départ, nous vous proposons deux autres exemples de soumissions. L'extracteur de caractéristiques est le même dans les trois. `source_rf` est similaire au kit de départ, mais utilise des arbres plus nombreux et plus profonds, pour obtenir un meilleur score. `target_rf` est une autre soumission extrême qui utilise seulement l'instance d'entraînement de la cible (peu) étiquetée pour apprendre un classificateur. Il a une performance légèrement moins bonne que `source_rf` ce qui signifie que les données sources améliorent le classificateur même si les distributions sources et cibles sont différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultats:\n",
    "|          | ap             | rec-5         | rec-10         | rec-20         | acc            |  auc           | \n",
    "|:---------|:--------------:|:-------------:|:--------------:|:--------------:|:--------------:|:--------------:|   \n",
    "|source_rf | 0.191 ± 0.0026 | 0.073 ± 0.002 | 0.176 ± 0.0032 | 0.357 ± 0.0075 | 0.84 ± 0.0014  | 0.637 ± 0.0063 | \n",
    "|target_rf | 0.163 ± 0.0218 | 0.067 ± 0.0182| 0.138 ± 0.0339 | 0.272 ± 0.0537 | 0.813 ± 0.036  | 0.591 ± 0.0399 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La grande question de l'apprentissage par transfert à résoudre est la suivante : **Comment combiner les données cibles à faible biais et à haute variance avec les données sources à faible biais et à haute variance**. D'autres questions auxquelles nous nous attendons à voir des réponses :\n",
    "\n",
    "1. Peut-on faire un meilleur prétraitement (amputation des données manquantes, utilisation du temps d'une manière plus intelligente) dans l'extracteur de caractéristiques ?\n",
    "2. Normalement, les données d'arrière-plan (bonnes instances) ne participent pas au scoring, mais elles peuvent informer le classifieur du changement de distribution. Comment utiliser au mieux cette information ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local testing (before submission)\n",
    "\n",
    "You submission will contain a `feature_extractor.py` implementing a FeatureExtractor class with a `transform` function (no `fit`) and a `classifier.py` implementing a Classifier class with a `fit` and `predict_proba` functions as in the starting kit. You should place it in the `submission/<submission_name>` folder in your RAMP kit folder. To test your submission, go to your RAMP kit folder in the terminal and type\n",
    "```\n",
    "ramp-test --submission <submission_name>\n",
    "```\n",
    "It will train and test your submission much like we did it above in this notebook, and print the foldwise and summary scores. You can try it also in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ramp-test --submission target_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a local leaderboard, use the `--save-output` option when running `ramp-test`, then try `ramp-show leaderboard` with different options. For example:\n",
    "```\n",
    "ramp-show leaderboard --mean --metric \"['ap','auc']\" --step \"['valid','test']\" --precision 3\n",
    "```\n",
    "and\n",
    "```\n",
    "ramp-show leaderboard --bagged --metric \"['auc']\"\n",
    "```\n",
    "\n",
    "RAMP also has an experimental hyperopt feature, with random grid search implemented. If you want to use it, type\n",
    "```\n",
    "ramp-hyperopt --help\n",
    "```\n",
    "and check out the example submission [here](https://github.com/ramp-kits/titanic/tree/hyperopt/submissions/starting_kit_h)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}